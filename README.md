# ğŸ§ SonicSync â€“ AI-Powered Equalizer & Genre Classifier

![SonicSync Architecture](./path-to/Screenshot%202025-04-18%20at%2011.12.45â€¯PM.png)

## Why AI in an Equalizer?

We all love listening to music. As the saying goes:

> _â€œMusic is like food â€” you donâ€™t need to know how itâ€™s made, as long as itâ€™s tasty!â€_

But just like food, everyone has a unique taste. Some prefer it spicy, others salty â€” the same applies to music. One song can sound different and better to each person with the right **Equalizer** (EQ) settings.

### So why use AI?

The world of equalizers is vast and technical. Not everyone is an audio expert, but everyone deserves a great listening experience. Our tool bridges that gap.

---

## ğŸ¯ Goal

To provide users with a **seamless, high-quality, and personalized music listening experience** by:

- Accurately classifying music genres
- Auto-tuning equalizer settings based on genre, user preferences, and headphones

---

## ğŸ’¡ Motivation

The rise of multimedia has flooded us with digital music, but:

- The experience isnâ€™t tailored for every user
- Manual EQ tweaking is not beginner-friendly

Our tool solves this by combining genre classification with automatic EQ adjustment.

---

## âš™ï¸ Challenges

- Accurately classifying music across a variety of genres and formats
- Dealing with different devices and headphone signatures
- Understanding both **spatial** (spectrogram) and **temporal** (sequence) audio features

---

## ğŸ§  Our Solution

- A **hybrid multi-model approach** combining:
  - CNNs for spatial audio features
  - BiLSTM for temporal dynamics
  - Random Forest for robust ensemble predictions
- Personalized EQ adjustments via **AutoEQ** based on:
  - Predicted genre
  - Userâ€™s headphones
  - Individual preferences

---

## ğŸ”® Future Work

- **Ensemble learning**: Combine outputs from multiple classifiers
- **Advanced Architectures**: Explore transformers and attention-based models
- **Mobile Application**: Real-time music classification and EQ on-the-go
- **Command-Line Support**: For power users and automation
- **Extended Features**: Playlist recommendations, live audio stream support, mood-based suggestions, etc.

---

## ğŸš€ How to Run This Project

### Backend Setup

1. Navigate to the backend directory:

   ```bash
   cd webapp
   ```

2. Install Python dependencies:

   ```bash
   python -m pip install -U -r requirements.txt
   ```

3. Start the backend server:
   ```bash
   uvicorn main:app --reload
   ```

The FastAPI backend will run on: `http://localhost:8000`

---

### Frontend Setup

1. Navigate to the frontend directory:

   ```bash
   cd ui
   ```

2. Install frontend dependencies:

   ```bash
   npm install
   ```

3. Start the frontend server:
   ```bash
   npm start
   ```

Visit: `http://localhost:3000` in your browser.

---

## âœ¨ Tech Stack

- **Frontend**: React.js (UI for genre display & EQ)
- **Backend**: FastAPI
- **ML Models**: Keras, PyTorch, RandomForest, Librosa
- **Audio Analysis**: MFCCs, Spectrograms
- **Equalizer Logic**: AutoEQ (custom frequency response modeling)

---

## ğŸ“‚ Project Structure

```
SonicSync/
â”‚
|
â”œâ”€â”€ main.py               # Backend - FastAPI
â”œâ”€â”€ genre_classifier.py
â”œâ”€â”€ ensemble_model.py
â”œâ”€â”€ model.pkl
|â”€â”€ ...
â”‚
â”œâ”€â”€ ui/                   # Frontend - React.js
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ audio/            # Audio samples
â”‚   â”œâ”€â”€ entries.json
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ temp_audio/           # Uploaded files (runtime)
â””â”€â”€ requirements.txt
```

---

## ğŸµ Experience the magic of AI + Audio

Get accurate genre predictions and auto-tuned audioâ€”just upload a track and let SonicSync do the rest ğŸ¶
